{"title":"Hypothesis testing","markdown":{"yaml":{"title":"Hypothesis testing","subtitle":"Data Science for Studying Language and the Mind","author":"Katie Schuler","date":"09-26-2023","echo":true,"format":{"revealjs":{"theme":"dark","slide-number":true,"incremental":true,"footer":"[https://kathrynschuler.com/datasci](https://kathrynschuler.com/datasci/)"}}},"headingText":"Explore a more complex dataset","containsRefs":false,"markdown":"\n\n\n```{r}\n#| echo: false\n#| message: false\n\nlibrary(tidyverse)\nlibrary(infer)\n\ntheme_set(theme_classic(base_size = 20))\nset.seed(60)\n\n```\n\n\n\n\n\n```{r}\n#| echo: false \n\nfemales <- tibble(\n    volume = rnorm(5625, mean = 1200, sd = 92),\n    sex = \"female\"\n)\n\nmales <- tibble(\n    volume = rnorm(5625, mean = 1220, sd = 98),\n    sex = \"male\"\n)\n\npenn_pop <- bind_rows(males, females)\npenn_sample <- penn_pop %>% slice_sample(n = 200)\npenn_sample_f <- filter(penn_sample, sex == \"female\")\npenn_sample_m <- filter(penn_sample, sex == \"male\")\n\nmean_f <- mean(penn_sample_f$volume)\nmean_m <- mean(penn_sample_m$volume)\n\n```\n\n## Last week: single quantity\n\nWe explored brain volume \n\n```{r}\npenn_sample %>%\n  ggplot(aes(x = volume)) +\n  geom_histogram(color = \"gray\")\n```\n\n## This week: two quantities\n\nBrain volume AND sex \n\n## Visualize with boxplot {.smaller}\n\nA useful visualization for a categorical variable is a boxplot: \n\n```{r}\npenn_sample %>%\n  ggplot(aes(y = volume, x = sex)) +\n  geom_boxplot(aes(color = sex))\n```\n\n## Observed difference in means {.smaller}\n\nDo the two sexes differ in mean brain volume?\n\n```{r}\nobs_diff <- penn_sample %>% \n  specify(response = volume, explanatory = sex) %>%\n  calculate(stat = \"diff in means\", order = c(\"male\", \"female\"))\n\nobs_diff\n```\n\n## Observed difference in means {.smaller}\n\nSampling variability or true difference in means?\n\n\n```{r}\n#| echo: false\nggplot(penn_pop, aes(x = volume)) +\n    geom_histogram(color = \"black\", fill = \"white\", position=\"identity\") +\n    geom_rug(data = penn_sample, aes(x = volume, color = sex))+\n    geom_vline(xintercept = mean_f, linewidth=2, color = \"red\") +\n    geom_vline(xintercept = mean_m, linewidth=2, color = \"blue\") +\n    scale_color_manual(values = c(\"red\", \"blue\"))\n  \n```\n\n\n# Hypothesis testing framework\n\n## 3-step process {.smaller}\n\nTo determine whether the brains of male and female Penn students differ with respect to the mean, we can use a framework for decision making called **hypothesis testing**. \n\n1. First we pose a **null hypothesis** that our result is due to nothing but chance (sampling variability)\n2. Then we ask: if the null hypothesis is true, how likely is our observed pattern of results? This liklihood is the **p-value**. \n3. Finally, if the p-value is less some threshold we decide upon (<0.05) then we **reject** the null hypothesis.\n\n## Step 1: Pose the null hypothesis {.smaller}\n\nWe pose a null hypothesis for practical reasons: it is the hypothesis for which we can simulate data. We can construct the sampling distribution for a hypothetical world in which our observed value is due to chance (we call this the **null distribution**). \n\n- To construct the null distribution we can use a process called **randomization**. \n- Randomization is similar to bootstrapping except, on each repeat, we will shuffle the sex and randomly assigning it to each participant. \n- This simulates a world in which there is no relationship between brain volume and sex.\n\n## Step 1: Pose the null hypothesis {.smaller}\n\n```{r}\n#| echo: false\n\n\nnull_distribution <- penn_sample %>% \n  specify(response = volume, explanatory = sex) %>%\n  hypothesize(null = \"independence\") %>%\n  generate(reps = 1000, type = \"permute\") %>%\n  calculate(stat = \"diff in means\", order = c(\"male\", \"female\")) \n\nnull_distribution %>% \n  visualize() + \n  labs(x = \"stat (difference in means)\")\n```\n\n## Step 2: How likely is our observed pattern? {.smaller}\n\nIf the null hypothesis is true, how likely is our observed pattern of results? \n\n- We can quantify this liklihood directly with the p-value: count the number of values in our null distribution that are more extreme than our observed value and divide that by the number of simulations we generated. \n\n. . . \n```{r}\nnull_distribution %>% \n  filter(abs(stat) > obs_diff$stat) %>%\n  summarise(p = n()/1000)\n```\n\n## Step 2: How likely is our observed pattern? {.smaller}\n\nOr `infer` can handle this for us with the `get_p_value()` function:\n\n```{r}\nnull_distribution %>%\n  get_p_value(obs_stat = obs_diff, direction = \"both\")\n```\n\n- A large p-value means our observed value is very likely under the null hypotheisis. \n- A small p-value means our observed value is very unlikely under the null hypothsis. \n\n## Step 2: How likely is our observed pattern? {.smaller}\n\n```{r}\n#| echo: false\n\n\nnull_distribution %>% \n  visualize() + \n  shade_p_value(obs_stat = obs_diff, direction = \"two-sided\") +\n  labs(x = \"stat (difference in means)\")\n\n```\n\n## Step 3: Decide whether to reject {.smaller}\n\nFinally, if the p-value is small enough — less than some threshold we decide upon — we reject the null hypothesis. By convention we consider a p-value less than 0.05 to be implausible enough that we can reject the null hypothesis. \n\n```{r}\n#| echo: false\n\n\nnull_distribution %>% \n  visualize() + \n  shade_p_value(obs_stat = obs_diff, direction = \"two-sided\") +\n  labs(x = \"stat (difference in means)\")\n\n```\n\n## Step 3: Decide whether to reject {.smaller}\n\nNote that obtaining our observed value is *implausible* under the null, but not *impossible*. In other words, our decision to reject (or not) could be wrong!\n\n- When we reject a null hypothesis that was actually true, we call it a **type I error**.\n- When we fail to reject a null hypothesis that was actually false, we call it a **type II error** \n\n## Remembering the error types {.smaller}\n\n![This figure borrowed from reddit can help you remember the error types. (Null hypothesis here is \"NOT pregnant\")](/include/figures/type1-type2-errors.png)\n\n# Demo the whole process\n\n# There is only one test\n\n## There is only one test {.smaller}\n\nIf you understand this framework, you can understand any hypothesis test (t-test, chi-squared, etc).\n\n![Figure borrowed from Modern Dive textbook](/include/figures/one-test.png){fig-align=\"center\" width=50%}\n\n\n## Two ways to simulate data {.smaller}\n\nRemember from last week that there are two ways we can construct a sampling distribution (simulate data):\n\n1. **Nonparametrically**, via brute computational force (simulating many repeats of the same experiment with bootstrapping or randomization) \n2. **Parametrically**, by assuming the data were sampled from known probability distribution and working out what happens theoretically under that distribution. \n\n## Demo with t-test \n\n# Exploring relationships\n\n```{r}\nlibrary(languageR)\n```\n\n## Visualize with scatter plot {.smaller}\n\nWe can explore the relationship between two quantities visually with a **scatter plot**.\n\n```{r}\n#| layout-ncol: 2\nratings %>% \n  ggplot(aes(x = Frequency, y = meanFamiliarity)) +\n  geom_point()\n\n```\n\n## Possible relationships {.smaller}\n\nIf there is no relationship between the variables, we say they are **independent**: knowing the value of one variable provides no information about the other variable.\n\n. . . \n\nIf there *is* some relationship between the variables, we can consider two types:\n\n1. There may be a **linear relationship** between the variables. When one goes up the other goes up (positive) or when one goes up the other goes down (negative). \n2. Or a **nonlinear relationship**. Nonlinear is a very broad category that encompasses all relationships that are not linear (e.g. a U-shaped curve).\n\n# Correlation\n\n## Correlation {.smaller}\n\nOne way to quantify linear relationships is with **correlation ($r$)**. Correlation expresses the linear relationship as a range from -1 to 1, where -1 means the relationship is perfectly negative and 1 means the relationship is perfectly positive. \n\n![Figure borrowed from iStock photos](/include/figures/correlation.jpeg){fig-align=\"center\" width=50%}\n\n## Correlation formally {.smaller}\n\nCorrelation can be calculated by taking the z-score of each variable (a normalization technique in which we subtract the mean and divide by the standard deviation) and then computing the average product of each variable: \n\n$r=\\frac{\\sum_{i=1}^n (\\frac{x_i - \\bar{x}}{sd(x)})(\\frac{y_i - \\bar{y}}{sd(y)})}{n}$\n\n## Correlation with R {.smaller}\n\nOr we can use R's built in correlation function: `cor(x,y)`\n\n```{r}\ncor(ratings$Frequency, ratings$meanFamiliarity)\n```\n\n## Correlation and sampling variability\n\nJust like the mean — and all other test statistics! — *$r$* is subject to sampling variability. We can indicate our uncertainty around the correlation we observe in the same way we did for the mean last week: construct the sampling distribution of the correlation via bootstrapping and compute a confidence interval. \n\n## Correlation and hypothesis testing\n\nHow do we test whether the correlation we observed in the data is significantly different from zero? We can use hypothesis testing (as learned today)! Here our null hypothesis that there is no relationship between the variables (they are **independent**). \n\n# Demo with correlation","srcMarkdownNoYaml":"\n\n\n```{r}\n#| echo: false\n#| message: false\n\nlibrary(tidyverse)\nlibrary(infer)\n\ntheme_set(theme_classic(base_size = 20))\nset.seed(60)\n\n```\n\n# Explore a more complex dataset \n\n\n\n\n```{r}\n#| echo: false \n\nfemales <- tibble(\n    volume = rnorm(5625, mean = 1200, sd = 92),\n    sex = \"female\"\n)\n\nmales <- tibble(\n    volume = rnorm(5625, mean = 1220, sd = 98),\n    sex = \"male\"\n)\n\npenn_pop <- bind_rows(males, females)\npenn_sample <- penn_pop %>% slice_sample(n = 200)\npenn_sample_f <- filter(penn_sample, sex == \"female\")\npenn_sample_m <- filter(penn_sample, sex == \"male\")\n\nmean_f <- mean(penn_sample_f$volume)\nmean_m <- mean(penn_sample_m$volume)\n\n```\n\n## Last week: single quantity\n\nWe explored brain volume \n\n```{r}\npenn_sample %>%\n  ggplot(aes(x = volume)) +\n  geom_histogram(color = \"gray\")\n```\n\n## This week: two quantities\n\nBrain volume AND sex \n\n## Visualize with boxplot {.smaller}\n\nA useful visualization for a categorical variable is a boxplot: \n\n```{r}\npenn_sample %>%\n  ggplot(aes(y = volume, x = sex)) +\n  geom_boxplot(aes(color = sex))\n```\n\n## Observed difference in means {.smaller}\n\nDo the two sexes differ in mean brain volume?\n\n```{r}\nobs_diff <- penn_sample %>% \n  specify(response = volume, explanatory = sex) %>%\n  calculate(stat = \"diff in means\", order = c(\"male\", \"female\"))\n\nobs_diff\n```\n\n## Observed difference in means {.smaller}\n\nSampling variability or true difference in means?\n\n\n```{r}\n#| echo: false\nggplot(penn_pop, aes(x = volume)) +\n    geom_histogram(color = \"black\", fill = \"white\", position=\"identity\") +\n    geom_rug(data = penn_sample, aes(x = volume, color = sex))+\n    geom_vline(xintercept = mean_f, linewidth=2, color = \"red\") +\n    geom_vline(xintercept = mean_m, linewidth=2, color = \"blue\") +\n    scale_color_manual(values = c(\"red\", \"blue\"))\n  \n```\n\n\n# Hypothesis testing framework\n\n## 3-step process {.smaller}\n\nTo determine whether the brains of male and female Penn students differ with respect to the mean, we can use a framework for decision making called **hypothesis testing**. \n\n1. First we pose a **null hypothesis** that our result is due to nothing but chance (sampling variability)\n2. Then we ask: if the null hypothesis is true, how likely is our observed pattern of results? This liklihood is the **p-value**. \n3. Finally, if the p-value is less some threshold we decide upon (<0.05) then we **reject** the null hypothesis.\n\n## Step 1: Pose the null hypothesis {.smaller}\n\nWe pose a null hypothesis for practical reasons: it is the hypothesis for which we can simulate data. We can construct the sampling distribution for a hypothetical world in which our observed value is due to chance (we call this the **null distribution**). \n\n- To construct the null distribution we can use a process called **randomization**. \n- Randomization is similar to bootstrapping except, on each repeat, we will shuffle the sex and randomly assigning it to each participant. \n- This simulates a world in which there is no relationship between brain volume and sex.\n\n## Step 1: Pose the null hypothesis {.smaller}\n\n```{r}\n#| echo: false\n\n\nnull_distribution <- penn_sample %>% \n  specify(response = volume, explanatory = sex) %>%\n  hypothesize(null = \"independence\") %>%\n  generate(reps = 1000, type = \"permute\") %>%\n  calculate(stat = \"diff in means\", order = c(\"male\", \"female\")) \n\nnull_distribution %>% \n  visualize() + \n  labs(x = \"stat (difference in means)\")\n```\n\n## Step 2: How likely is our observed pattern? {.smaller}\n\nIf the null hypothesis is true, how likely is our observed pattern of results? \n\n- We can quantify this liklihood directly with the p-value: count the number of values in our null distribution that are more extreme than our observed value and divide that by the number of simulations we generated. \n\n. . . \n```{r}\nnull_distribution %>% \n  filter(abs(stat) > obs_diff$stat) %>%\n  summarise(p = n()/1000)\n```\n\n## Step 2: How likely is our observed pattern? {.smaller}\n\nOr `infer` can handle this for us with the `get_p_value()` function:\n\n```{r}\nnull_distribution %>%\n  get_p_value(obs_stat = obs_diff, direction = \"both\")\n```\n\n- A large p-value means our observed value is very likely under the null hypotheisis. \n- A small p-value means our observed value is very unlikely under the null hypothsis. \n\n## Step 2: How likely is our observed pattern? {.smaller}\n\n```{r}\n#| echo: false\n\n\nnull_distribution %>% \n  visualize() + \n  shade_p_value(obs_stat = obs_diff, direction = \"two-sided\") +\n  labs(x = \"stat (difference in means)\")\n\n```\n\n## Step 3: Decide whether to reject {.smaller}\n\nFinally, if the p-value is small enough — less than some threshold we decide upon — we reject the null hypothesis. By convention we consider a p-value less than 0.05 to be implausible enough that we can reject the null hypothesis. \n\n```{r}\n#| echo: false\n\n\nnull_distribution %>% \n  visualize() + \n  shade_p_value(obs_stat = obs_diff, direction = \"two-sided\") +\n  labs(x = \"stat (difference in means)\")\n\n```\n\n## Step 3: Decide whether to reject {.smaller}\n\nNote that obtaining our observed value is *implausible* under the null, but not *impossible*. In other words, our decision to reject (or not) could be wrong!\n\n- When we reject a null hypothesis that was actually true, we call it a **type I error**.\n- When we fail to reject a null hypothesis that was actually false, we call it a **type II error** \n\n## Remembering the error types {.smaller}\n\n![This figure borrowed from reddit can help you remember the error types. (Null hypothesis here is \"NOT pregnant\")](/include/figures/type1-type2-errors.png)\n\n# Demo the whole process\n\n# There is only one test\n\n## There is only one test {.smaller}\n\nIf you understand this framework, you can understand any hypothesis test (t-test, chi-squared, etc).\n\n![Figure borrowed from Modern Dive textbook](/include/figures/one-test.png){fig-align=\"center\" width=50%}\n\n\n## Two ways to simulate data {.smaller}\n\nRemember from last week that there are two ways we can construct a sampling distribution (simulate data):\n\n1. **Nonparametrically**, via brute computational force (simulating many repeats of the same experiment with bootstrapping or randomization) \n2. **Parametrically**, by assuming the data were sampled from known probability distribution and working out what happens theoretically under that distribution. \n\n## Demo with t-test \n\n# Exploring relationships\n\n```{r}\nlibrary(languageR)\n```\n\n## Visualize with scatter plot {.smaller}\n\nWe can explore the relationship between two quantities visually with a **scatter plot**.\n\n```{r}\n#| layout-ncol: 2\nratings %>% \n  ggplot(aes(x = Frequency, y = meanFamiliarity)) +\n  geom_point()\n\n```\n\n## Possible relationships {.smaller}\n\nIf there is no relationship between the variables, we say they are **independent**: knowing the value of one variable provides no information about the other variable.\n\n. . . \n\nIf there *is* some relationship between the variables, we can consider two types:\n\n1. There may be a **linear relationship** between the variables. When one goes up the other goes up (positive) or when one goes up the other goes down (negative). \n2. Or a **nonlinear relationship**. Nonlinear is a very broad category that encompasses all relationships that are not linear (e.g. a U-shaped curve).\n\n# Correlation\n\n## Correlation {.smaller}\n\nOne way to quantify linear relationships is with **correlation ($r$)**. Correlation expresses the linear relationship as a range from -1 to 1, where -1 means the relationship is perfectly negative and 1 means the relationship is perfectly positive. \n\n![Figure borrowed from iStock photos](/include/figures/correlation.jpeg){fig-align=\"center\" width=50%}\n\n## Correlation formally {.smaller}\n\nCorrelation can be calculated by taking the z-score of each variable (a normalization technique in which we subtract the mean and divide by the standard deviation) and then computing the average product of each variable: \n\n$r=\\frac{\\sum_{i=1}^n (\\frac{x_i - \\bar{x}}{sd(x)})(\\frac{y_i - \\bar{y}}{sd(y)})}{n}$\n\n## Correlation with R {.smaller}\n\nOr we can use R's built in correlation function: `cor(x,y)`\n\n```{r}\ncor(ratings$Frequency, ratings$meanFamiliarity)\n```\n\n## Correlation and sampling variability\n\nJust like the mean — and all other test statistics! — *$r$* is subject to sampling variability. We can indicate our uncertainty around the correlation we observe in the same way we did for the mean last week: construct the sampling distribution of the correlation via bootstrapping and compute a confidence interval. \n\n## Correlation and hypothesis testing\n\nHow do we test whether the correlation we observed in the data is significantly different from zero? We can use hypothesis testing (as learned today)! Here our null hypothesis that there is no relationship between the variables (they are **independent**). \n\n# Demo with correlation"},"formats":{"revealjs":{"identifier":{"display-name":"RevealJS","target-format":"revealjs","base-format":"revealjs"},"execute":{"fig-width":10,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","html-math-method":{"method":"mathjax","url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML-full"},"slide-level":2,"to":"revealjs","incremental":true,"output-file":"hypothesis-testing.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":false,"quarto-version":"1.3.353","auto-stretch":true,"callout-appearance":"simple","title":"Hypothesis testing","subtitle":"Data Science for Studying Language and the Mind","author":"Katie Schuler","date":"09-26-2023","theme":"dark","slideNumber":true,"footer":"[https://kathrynschuler.com/datasci](https://kathrynschuler.com/datasci/)"}}},"projectFormats":["html"]}