{"title":"Data Importing","markdown":{"yaml":{"title":"Data Importing","subtitle":"Data Science for Studying Language and the Mind","author":"Katie Schuler","date":"09-05-2023","echo":true,"format":{"revealjs":{"theme":"dark","incremental":true,"footer":"[https://kathrynschuler.com/datasci](https://kathrynschuler.com/datasci/)"}}},"headingText":"Problem Set 1 ","headingAttr":{"id":"","classes":["smaller"],"keyvalue":[]},"containsRefs":false,"markdown":"\n\n- due Sunday 11:59pm\n- Get support by: \n    - Asking specific Qs on Ed\n    - Come to office hours \n    - Get a pset buddy\n- But we will `not`:\n    - Answer \"is this correct?\"\n    - Give feedback on your entire pset before deadline\n    - Go over the pset in lab \n\n## Last week \n\n- Basic concepts\n- Important functions\n- Vectors \n- Operations\n- [Subsetting](https://kathrynschuler.com/datasci/slides/r-basics.html#/ways-to-extract-a-single-element) - stopped here \n- Built-in functions\n- Missing values\n- Programming\n\n## You are `here` {.smaller} \n\n:::: {.columns}\n\n::: {.column width=\"33%\"}\n\n##### Data science with R \n::: {.nonincremental}\n- Hello, world!\n- R basics\n- `Data importing`\n- Data visualization \n- Data wrangling \n:::\n:::\n\n::: {.column width=\"33%\"}\n\n##### Stats & Model buidling\n::: {.nonincremental}\n- Probability distributions\n- Sampling variability\n- Hypothesis testing\n- Model specification\n- Model fitting \n- Model accuracy\n- Model reliability\n:::\n:::\n\n::: {.column width=\"33%\"}\n\n##### More advanced \n::: {.nonincremental}\n\n- Classification\n- Feature engineering (preprocessing) \n- Inference for regression\n- Mixed-effect models\n::: \n:::\n\n::::\n\n## Overview for today\n\n- Tidyverse\n- Tidy data \n- `purr`  - functional programming\n- `tibble` - modern data.frame\n- `readr` - reading data\n\n# Tidyverse \n> The tidyverse is an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures. \n> \n> [Tidyverse package docs](https://www.tidyverse.org/)\n\n## Tidyverse {.smaller}\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n- `ggplot2` - for data visualization\n- `dplyr` - for data wrangling\n- `readr` - for reading data\n- `tibble` - for modern data frames\n- `stringr`: for string manipulation\n- `forcats`: for dealing with factors\n- `tidyr`: for data tidying\n- `purrr`: for functional programming\n:::\n\n::: {.column width=\"50%\"}\n\n![Tidyverse hex logos from www.tidyverse.org](/include/figures/tidyverse-hexlogos.png){#fig-tidyverse fig-align=\"center\" width=100%}\n:::\n\n::::\n\n## Loading the tidyverse\n\nAlready installed on Google Colab's R kernel:\n\n```{r}\n#| echo: true\nlibrary(tidyverse)\n```\n\nMessage: \n\n- a list of packages loaded\n- a warning of potential name conflicts \n \n\n## Tidy data\n\nTidyverse makes use of tidy data, a standard way of structuring datasets: \n\n1. each variable forms a **column**; each column forms a variable\n2. each observation forms a **row**; each row forms an observation\n3. value is a **cell**; each cell is a single value\n\n## Tidy data {.smaller}\n\n![Visual of tidy data rules, from R for Data Science](/include/figures/tidy-data.png){#fig-tidydata fig-align=\"center\" width=80%}\n\nWhy tidy data? \n\n- Because consistency and uniformity are very helpful when programming\n- Variables as columns works well for vectorized languages (R!)\n\n\n# `purr`\nFunctional programming\n\nto illustrate the joy of `tidyverse` and tidy data\n\n## `purr`\n\n> purrr enhances R’s functional programming (FP) toolkit by providing a complete and consistent set of tools for working with functions and vectors. If you’ve never heard of FP before, the best place to start is the family of map() functions which allow you to replace many for loops with code that is both more succinct and easier to read.\n> \n> [purrr docs](https://purrr.tidyverse.org/)\n\n## The `map_*()` functions\n\n1. Take a vector as input\n2. Apply a function to each element\n3. Return a new vector \n\n##  The `map_*()` functions\n\nWe say \"functions\" because there are 5, one for each type of vector: \n\n- `map()` - list\n- `map_lgl()` - logical\n- `map_int()` - integer\n- `map_dbl()` - double\n- `map_chr()` - character\n\n## `map` use case\n\n```{r}\n\ndf <- data.frame(\n    x = 1:10,\n    y = 11:20,\n    z = 21:30\n)\n```\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\nwith copy+paste\n```{r}\nmean(df$x)\nmean(df$y)\nmean(df$z)\n```\n\n:::\n\n::: {.column width=\"50%\"}\nwith `map`\n```{r}\nmap(df, mean)\n```\n\n:::\n::::\n\n# `tibble`\nmodern data frames\n\n## `tibble`\n\n> A tibble, or tbl_df, is a modern reimagining of the data.frame, keeping what time has proven to be effective, and throwing out what is not. Tibbles are data.frames that are lazy and surly: they do less and complain more\n> \n> [tibble docs](https://tibble.tidyverse.org/)\n\n## `tibble` \n\nTibbles do less than data frames, in a good way: \n\n- never changes type of input (never converts strings to factors!)\n- never changes the name of variables \n- only recycles vectors of length 1\n- never creates row names \n\n\n::: aside\nThe take-away is that `data.frame` and `tibble` sometimes behave differently. The behavior of `tibble` makes more sense for modern data science, so we should us it instead!\n:::\n\n## Create a `tibble` {.smaller}\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\nCoerce an existing object:\n```{r}\ndf <- data.frame(\n    x = 1:4,\n    y = c(\"a\", \"b\", \"c\", \"d\")\n)\nas_tibble(df)\n```\n\nPass a column of vectors: \n```{r}\ntibble(\n    x = 1:4,\n    y = c(\"a\", \"b\", \"c\", \"d\")\n)\n```\n\n\n:::\n::: {.column width=\"50%\"}\n\nDefine row-by-row:\n\n```{r}\ntribble(\n    ~x, ~y,\n    \"a\", 1,\n    \"b\", 2,\n    \"c\", 3,\n    \"d\", 4 \n)\n```\n\n:::\n::::\n\n## Test if `tibble`\n\nWith `is_tibble(x)` and `is.data.frame(x)`\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\nData frame:\n\n```{r}\ndf <- data.frame(\n    x = 1:4,\n    y = c(\"a\", \"b\", \"c\", \"d\")\n)\n```\n\n```{r}\nis_tibble(df)\nis.data.frame(df)\n```\n\n\n:::\n::: {.column width=\"50%\"}\n\nTibble:\n\n```{r}\ntib <- tribble(\n    ~x, ~y,\n    \"a\", 1,\n    \"b\", 2,\n    \"c\", 3,\n    \"d\", 4 \n)\n```\n\n```{r}\nis_tibble(tib)\nis.data.frame(tib)\n```\n\n:::\n::::\n\n## `data.frame` v `tibble` {.smaller}\n\nYou will encounter 2 main diffs:\n\n1. **printing** \n    - by default, tibbles print the first 10 rows and all columns that fit on screen, making it easier to work with large datasets. \n    - also report the type of each column (e.g. `<dbl>`, `<chr>`)\n2. **subsetting** - tibbles are more strict than data frames, which fixes two quirks we encountered last lecture when subsetting with `[[` and `$`:\n    - tibbles *never* do partial matching\n    - they *always* generate a warning if the column you are trying to extract does not exist.\n\n# `readr`\nreading data \n\n## `readr`\n\n> The goal of readr is to provide a fast and friendly way to read rectangular data from delimited files, such as comma-separated values (CSV) and tab-separated values (TSV). It is designed to parse many types of data found in the wild, while providing an informative problem report when parsing leads to unexpected results.\n> \n> [readr docs](https://readr.tidyverse.org/)\n\n## Rectangular data\n\n![Sample csv file from R for Data Science](/include/figures/rectangle-data.png){#fig-rectangledata fig-align=\"center\" width=80%}\n\n## `read_*()`\n\nThe `read_*()` functions have two important arguments: \n\n1. `file` - the path to the file \n2. `col_types` - a list of how each column should be converted to a specific data type\n\n## 7 supported file types, `read_*()`\n\n- `read_csv()`: comma-separated values (CSV)\n- `read_tsv()`: tab-separated values (TSV)\n- `read_csv2()`: semicolon-separated values\n- `read_delim()`: delimited files (CSV and TSV are important special cases)\n- `read_fwf()`: fixed-width files\n- `read_table()`: whitespace-separated files\n- `read_log()`: web log files\n\n## Read `csv` files \n\nPath only, `readr` guesses types: \n\n```r\nread_csv(file='\"https://pos.it/r4ds-students-csv\"')\n\n```\n. . .\n\nPath and specify col_types:\n```r\nread_csv(\n    file='\"https://pos.it/r4ds-students-csv\"', \n    col_types = list( x = col_string(), y = col_skip() )\n)\n```\n\n::: aside\nGuessing heuristic: character > date-time > double > logical\n:::\n\n\n## `col_types` column specification {.smaller}\n\nThere are 11 column types that can be specified: \n\n- `col_logical()` - reads as boolean TRUE FALSE values\n- `col_integer()` - reads as integer\n- `col_double()` - reads as double\n- `col_number()` - numeric parser that can ignore non-numbers\n- `col_character()` - reads as strings\n- `col_factor(levels, ordered = FALSE)` - creates factors\n- `col_datetime(format = \"\")` - creates date-times\n- `col_date(format = \"\")` - creates dates\n- `col_time(format = \"\")` - creates times\n- `col_skip()` - skips a column \n- `col_guess()` - tries to guess the column\n\n## Reading more complex files {.smaller}\n\nReading more complex file types requires functions outside the tidyverse:\n\n- **excel** with `readxl` - see [Spreadsheets](https://r4ds.hadley.nz/spreadsheets#excel) in R for Data Science\n- **google sheets**  with `googlesheets4` - see [Spreadsheets](https://r4ds.hadley.nz/spreadsheets#google-sheets) in R for Data Science\n- **databases** with `DBI` - see [Databases](https://r4ds.hadley.nz/databases) in R for Data Science\n- **json data** with `jsonlite` - see [Hierarchical data](https://r4ds.hadley.nz/rectangling) in R for Data Science\n\n## Writing to a file\n\nWrite to a .csv file with\n\n```r\nwrite_csv(students, \"students.csv\")\n```\n\n:::aside\narguments: tibble, name to give file\n:::\n\n# Common problems `readr`\n\n## Column contains unexpected values\n\nYour dataset has a column that you expected to be `logical` or `double`, but there is a typo somewhere, so R has coerced the column into `character`. \n\n. . . \n\nSolve by specifying the column type `col_double()` and then using the `problems()` function to see where R failed.\n\n## Missing values are not `NA`\n \nYour dataset has missing values, but they were not coded as `NA` as R expects. \n\n. . . \n\nSolve by adding an `na` argument (e.g. `na=c(\"N/A\")`)\n\n## Column names have spaces \n\nYour dataset has column names that include spaces, breaking R's naming rules. In these cases, R adds backticks (e.g. `` `brain size` ``); \n . . . \n\nWe can use the `rename()` function to fix them. \n\n::: aside\nIf we have a lot to rename and that gets annoying, see `janitor::clean_names()`.\n:::\n\n\n\n# Questions? \n","srcMarkdownNoYaml":"\n## Problem Set 1  {.smaller}\n\n- due Sunday 11:59pm\n- Get support by: \n    - Asking specific Qs on Ed\n    - Come to office hours \n    - Get a pset buddy\n- But we will `not`:\n    - Answer \"is this correct?\"\n    - Give feedback on your entire pset before deadline\n    - Go over the pset in lab \n\n## Last week \n\n- Basic concepts\n- Important functions\n- Vectors \n- Operations\n- [Subsetting](https://kathrynschuler.com/datasci/slides/r-basics.html#/ways-to-extract-a-single-element) - stopped here \n- Built-in functions\n- Missing values\n- Programming\n\n## You are `here` {.smaller} \n\n:::: {.columns}\n\n::: {.column width=\"33%\"}\n\n##### Data science with R \n::: {.nonincremental}\n- Hello, world!\n- R basics\n- `Data importing`\n- Data visualization \n- Data wrangling \n:::\n:::\n\n::: {.column width=\"33%\"}\n\n##### Stats & Model buidling\n::: {.nonincremental}\n- Probability distributions\n- Sampling variability\n- Hypothesis testing\n- Model specification\n- Model fitting \n- Model accuracy\n- Model reliability\n:::\n:::\n\n::: {.column width=\"33%\"}\n\n##### More advanced \n::: {.nonincremental}\n\n- Classification\n- Feature engineering (preprocessing) \n- Inference for regression\n- Mixed-effect models\n::: \n:::\n\n::::\n\n## Overview for today\n\n- Tidyverse\n- Tidy data \n- `purr`  - functional programming\n- `tibble` - modern data.frame\n- `readr` - reading data\n\n# Tidyverse \n> The tidyverse is an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures. \n> \n> [Tidyverse package docs](https://www.tidyverse.org/)\n\n## Tidyverse {.smaller}\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n- `ggplot2` - for data visualization\n- `dplyr` - for data wrangling\n- `readr` - for reading data\n- `tibble` - for modern data frames\n- `stringr`: for string manipulation\n- `forcats`: for dealing with factors\n- `tidyr`: for data tidying\n- `purrr`: for functional programming\n:::\n\n::: {.column width=\"50%\"}\n\n![Tidyverse hex logos from www.tidyverse.org](/include/figures/tidyverse-hexlogos.png){#fig-tidyverse fig-align=\"center\" width=100%}\n:::\n\n::::\n\n## Loading the tidyverse\n\nAlready installed on Google Colab's R kernel:\n\n```{r}\n#| echo: true\nlibrary(tidyverse)\n```\n\nMessage: \n\n- a list of packages loaded\n- a warning of potential name conflicts \n \n\n## Tidy data\n\nTidyverse makes use of tidy data, a standard way of structuring datasets: \n\n1. each variable forms a **column**; each column forms a variable\n2. each observation forms a **row**; each row forms an observation\n3. value is a **cell**; each cell is a single value\n\n## Tidy data {.smaller}\n\n![Visual of tidy data rules, from R for Data Science](/include/figures/tidy-data.png){#fig-tidydata fig-align=\"center\" width=80%}\n\nWhy tidy data? \n\n- Because consistency and uniformity are very helpful when programming\n- Variables as columns works well for vectorized languages (R!)\n\n\n# `purr`\nFunctional programming\n\nto illustrate the joy of `tidyverse` and tidy data\n\n## `purr`\n\n> purrr enhances R’s functional programming (FP) toolkit by providing a complete and consistent set of tools for working with functions and vectors. If you’ve never heard of FP before, the best place to start is the family of map() functions which allow you to replace many for loops with code that is both more succinct and easier to read.\n> \n> [purrr docs](https://purrr.tidyverse.org/)\n\n## The `map_*()` functions\n\n1. Take a vector as input\n2. Apply a function to each element\n3. Return a new vector \n\n##  The `map_*()` functions\n\nWe say \"functions\" because there are 5, one for each type of vector: \n\n- `map()` - list\n- `map_lgl()` - logical\n- `map_int()` - integer\n- `map_dbl()` - double\n- `map_chr()` - character\n\n## `map` use case\n\n```{r}\n\ndf <- data.frame(\n    x = 1:10,\n    y = 11:20,\n    z = 21:30\n)\n```\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\nwith copy+paste\n```{r}\nmean(df$x)\nmean(df$y)\nmean(df$z)\n```\n\n:::\n\n::: {.column width=\"50%\"}\nwith `map`\n```{r}\nmap(df, mean)\n```\n\n:::\n::::\n\n# `tibble`\nmodern data frames\n\n## `tibble`\n\n> A tibble, or tbl_df, is a modern reimagining of the data.frame, keeping what time has proven to be effective, and throwing out what is not. Tibbles are data.frames that are lazy and surly: they do less and complain more\n> \n> [tibble docs](https://tibble.tidyverse.org/)\n\n## `tibble` \n\nTibbles do less than data frames, in a good way: \n\n- never changes type of input (never converts strings to factors!)\n- never changes the name of variables \n- only recycles vectors of length 1\n- never creates row names \n\n\n::: aside\nThe take-away is that `data.frame` and `tibble` sometimes behave differently. The behavior of `tibble` makes more sense for modern data science, so we should us it instead!\n:::\n\n## Create a `tibble` {.smaller}\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\nCoerce an existing object:\n```{r}\ndf <- data.frame(\n    x = 1:4,\n    y = c(\"a\", \"b\", \"c\", \"d\")\n)\nas_tibble(df)\n```\n\nPass a column of vectors: \n```{r}\ntibble(\n    x = 1:4,\n    y = c(\"a\", \"b\", \"c\", \"d\")\n)\n```\n\n\n:::\n::: {.column width=\"50%\"}\n\nDefine row-by-row:\n\n```{r}\ntribble(\n    ~x, ~y,\n    \"a\", 1,\n    \"b\", 2,\n    \"c\", 3,\n    \"d\", 4 \n)\n```\n\n:::\n::::\n\n## Test if `tibble`\n\nWith `is_tibble(x)` and `is.data.frame(x)`\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\nData frame:\n\n```{r}\ndf <- data.frame(\n    x = 1:4,\n    y = c(\"a\", \"b\", \"c\", \"d\")\n)\n```\n\n```{r}\nis_tibble(df)\nis.data.frame(df)\n```\n\n\n:::\n::: {.column width=\"50%\"}\n\nTibble:\n\n```{r}\ntib <- tribble(\n    ~x, ~y,\n    \"a\", 1,\n    \"b\", 2,\n    \"c\", 3,\n    \"d\", 4 \n)\n```\n\n```{r}\nis_tibble(tib)\nis.data.frame(tib)\n```\n\n:::\n::::\n\n## `data.frame` v `tibble` {.smaller}\n\nYou will encounter 2 main diffs:\n\n1. **printing** \n    - by default, tibbles print the first 10 rows and all columns that fit on screen, making it easier to work with large datasets. \n    - also report the type of each column (e.g. `<dbl>`, `<chr>`)\n2. **subsetting** - tibbles are more strict than data frames, which fixes two quirks we encountered last lecture when subsetting with `[[` and `$`:\n    - tibbles *never* do partial matching\n    - they *always* generate a warning if the column you are trying to extract does not exist.\n\n# `readr`\nreading data \n\n## `readr`\n\n> The goal of readr is to provide a fast and friendly way to read rectangular data from delimited files, such as comma-separated values (CSV) and tab-separated values (TSV). It is designed to parse many types of data found in the wild, while providing an informative problem report when parsing leads to unexpected results.\n> \n> [readr docs](https://readr.tidyverse.org/)\n\n## Rectangular data\n\n![Sample csv file from R for Data Science](/include/figures/rectangle-data.png){#fig-rectangledata fig-align=\"center\" width=80%}\n\n## `read_*()`\n\nThe `read_*()` functions have two important arguments: \n\n1. `file` - the path to the file \n2. `col_types` - a list of how each column should be converted to a specific data type\n\n## 7 supported file types, `read_*()`\n\n- `read_csv()`: comma-separated values (CSV)\n- `read_tsv()`: tab-separated values (TSV)\n- `read_csv2()`: semicolon-separated values\n- `read_delim()`: delimited files (CSV and TSV are important special cases)\n- `read_fwf()`: fixed-width files\n- `read_table()`: whitespace-separated files\n- `read_log()`: web log files\n\n## Read `csv` files \n\nPath only, `readr` guesses types: \n\n```r\nread_csv(file='\"https://pos.it/r4ds-students-csv\"')\n\n```\n. . .\n\nPath and specify col_types:\n```r\nread_csv(\n    file='\"https://pos.it/r4ds-students-csv\"', \n    col_types = list( x = col_string(), y = col_skip() )\n)\n```\n\n::: aside\nGuessing heuristic: character > date-time > double > logical\n:::\n\n\n## `col_types` column specification {.smaller}\n\nThere are 11 column types that can be specified: \n\n- `col_logical()` - reads as boolean TRUE FALSE values\n- `col_integer()` - reads as integer\n- `col_double()` - reads as double\n- `col_number()` - numeric parser that can ignore non-numbers\n- `col_character()` - reads as strings\n- `col_factor(levels, ordered = FALSE)` - creates factors\n- `col_datetime(format = \"\")` - creates date-times\n- `col_date(format = \"\")` - creates dates\n- `col_time(format = \"\")` - creates times\n- `col_skip()` - skips a column \n- `col_guess()` - tries to guess the column\n\n## Reading more complex files {.smaller}\n\nReading more complex file types requires functions outside the tidyverse:\n\n- **excel** with `readxl` - see [Spreadsheets](https://r4ds.hadley.nz/spreadsheets#excel) in R for Data Science\n- **google sheets**  with `googlesheets4` - see [Spreadsheets](https://r4ds.hadley.nz/spreadsheets#google-sheets) in R for Data Science\n- **databases** with `DBI` - see [Databases](https://r4ds.hadley.nz/databases) in R for Data Science\n- **json data** with `jsonlite` - see [Hierarchical data](https://r4ds.hadley.nz/rectangling) in R for Data Science\n\n## Writing to a file\n\nWrite to a .csv file with\n\n```r\nwrite_csv(students, \"students.csv\")\n```\n\n:::aside\narguments: tibble, name to give file\n:::\n\n# Common problems `readr`\n\n## Column contains unexpected values\n\nYour dataset has a column that you expected to be `logical` or `double`, but there is a typo somewhere, so R has coerced the column into `character`. \n\n. . . \n\nSolve by specifying the column type `col_double()` and then using the `problems()` function to see where R failed.\n\n## Missing values are not `NA`\n \nYour dataset has missing values, but they were not coded as `NA` as R expects. \n\n. . . \n\nSolve by adding an `na` argument (e.g. `na=c(\"N/A\")`)\n\n## Column names have spaces \n\nYour dataset has column names that include spaces, breaking R's naming rules. In these cases, R adds backticks (e.g. `` `brain size` ``); \n . . . \n\nWe can use the `rename()` function to fix them. \n\n::: aside\nIf we have a lot to rename and that gets annoying, see `janitor::clean_names()`.\n:::\n\n\n\n# Questions? \n"},"formats":{"revealjs":{"identifier":{"display-name":"RevealJS","target-format":"revealjs","base-format":"revealjs"},"execute":{"fig-width":10,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","html-math-method":{"method":"mathjax","url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML-full"},"slide-level":2,"to":"revealjs","incremental":true,"output-file":"data-importing.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":false,"quarto-version":"1.3.353","auto-stretch":true,"callout-appearance":"simple","title":"Data Importing","subtitle":"Data Science for Studying Language and the Mind","author":"Katie Schuler","date":"09-05-2023","theme":"dark","footer":"[https://kathrynschuler.com/datasci](https://kathrynschuler.com/datasci/)"}}},"projectFormats":["html"]}