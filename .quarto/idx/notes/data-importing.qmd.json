{"title":"Data importing","markdown":{"yaml":{"title":"Data importing","date":"09/05/2023","author":["Katie Schuler"]},"headingText":"Welcome to the tidyverse","containsRefs":false,"markdown":"\n\n\n> The tidyverse is an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures. ~ [Tidyverse package docs](https://www.tidyverse.org/)\n\nThe `tidyverse` collection of packages includes: \n\n- `ggplot2` - for data visualization\n- `dplyr` - for data wrangling\n- `readr` - for reading data\n- `tibble` - for modern data frames\n- `stringr`: for string manipulation\n- `forcats`: for dealing with factors\n- `tidyr`: for data tidying\n- `purrr`: for functional programming\n- `lubridate`: for working with dates and times\n\nWe load the `tidyverse` like any other package, with `library(tidyverse)`. When we do, we will receive a message with (1) a list packages that were loaded and (2) a warning that there are potential conflicts with base R's `stats` functions\n\n- We can resolve conflicts with the `::` operator, which allows us to specify which package our intended function belongs to as a prefix: `stats::filter()` or `dplyr::filter()`\n\n## What is tidy data?\n\nThe same underlying data can be represented in a table in many different ways; some easier to work with than others. The tidyverse makes use of tidy data principles to make datasets easier to work with in R. **Tidy data** provides a standard way of structuring datasets: \n\n1. each variable forms a **column**; each column forms a variable\n2. each observation forms a **row**; each row forms an observation\n3. value is a **cell**; each cell is a single value\n\n\nWhy is tidy data easier to work with? \n\n- Because consistency and uniformity are very helpful when programming\n- Variables as columns works well for vectorized languages (R!)\n\n## Functional programming with purrr\n\n> purrr enhances R’s functional programming (FP) toolkit by providing a complete and consistent set of tools for working with functions and vectors. If you’ve never heard of FP before, the best place to start is the family of map() functions which allow you to replace many for loops with code that is both more succinct and easier to read.  ~ [purrr docs](https://purrr.tidyverse.org/)\n\nLet's illustrate the joy of the tidyverse with one of its packages: `purrr`. The docs say that the best place to start is the family of `map()` functions, so we'll do that.\n\nThe `map()` functions:\n\n1. take a vector as input\n2. apply a function to each element\n3. return a new vector\n\nWe say \"functions\" because there are 5, the generic `map()` function and `map_*()` variants for each type of vector: \n\n- `map()`\n- `map_lgl()`\n- `map_int()`\n- `map_dbl()`\n- `map_chr()` \n\nTo illustrate, suppose we have a data frame `df` with 3 columns and we want to compute the mean of each column. We could solve this with copy-and-paste (run `mean()` 3 different times) or try to use a `for` loop, but `map()` can do this with just one line: \n\n```r\n# We use `map_dbl()` because `mean()` returns a *double* value\nmap_dbl(df, mean)\n```\n\n\n## Modern data frames with tibble\n\n> A tibble, or tbl_df, is a modern reimagining of the data.frame, keeping what time has proven to be effective, and throwing out what is not. Tibbles are data.frames that are lazy and surly: they do less and complain more ~ [tibble docs](https://tibble.tidyverse.org/)\n\nTibbles do less than data frames, in a good way: \n\n- never changes type of input (never converts strings to factors!)\n- never changes the name of variables \n- only recycles vectors of length 1\n- never creates row names \n\nYou can read more in the [tibble vignette](https://tibble.tidyverse.org/articles/tibble.html) if you are interested, but understanding these differences is not necessary to be successful in the course. The take-away is that `data.frame` and `tibble` sometimes behave differently. The behavior of `tibble` makes more sense for modern data science, so we should us it instead!\n\nCreate a `tibble` with one of the following:  \n\n```r\n# (1) coerce an existing object (e.g., a data frame) to tibble\nas_tibble(x)\n\n# (2) construct a tibble from a column of vectors\ntibble(x=1:5, y=1)\n\n# (3) define row-by-row, short for transposed tibble\ntribble(\n    ~x, ~y, ~z,\n    \"a\", 2, 3.6,\n    \"b\", 1, 8.5\n)\n```\n\nWe will encounter two main ways tibbles and data frames differ: \n\n- **printing** - by default, tibbles print the first 10 rows and all columns that fit on screen, making it easier to work with large datasets. Tibbles also report the type of each column (e.g. `<dbl>`, `<chr>`)\n- **subsetting** - tibbles are more strict than data frames, which fixes two quirks we encountered last lecture when subsetting with `[[` and `$`: (1) tibbles *never* do partial matching, and (2) they *always* generate a warning if the column you are trying to extract does not exist.\n\nTo test if something is a `tibble` or a `data.frame`: \n\n- `is_tibble(x)`\n- `is.data.frame(x)`\n\n## Reading data with readr\n\n> The goal of readr is to provide a fast and friendly way to read rectangular data from delimited files, such as comma-separated values (CSV) and tab-separated values (TSV). It is designed to parse many types of data found in the wild, while providing an informative problem report when parsing leads to unexpected results.\n> \n> [readr docs](https://readr.tidyverse.org/)\n\nOften we want to read in some data we've generated or collected outside of R. The most basic and common format is plain-text **rectangular** files. We will \"read\" these into R with readr's `read_*()` functions.\n\nThe `read_*()` functions have two important arguments: \n\n- `file` - the path to the file (that reader will try to parse)\n- `col_types` - **column specification**, a description of how each column should be converted from a character vector to a specific data type\n\nThere are 7 supported file types, each with their own `read_*()` function:\n\n- `read_csv()`: comma-separated values (CSV)\n- `read_tsv()`: tab-separated values (TSV)\n- `read_csv2()`: semicolon-separated values\n- `read_delim()`: delimited files (CSV and TSV are important special cases)\n- `read_fwf()`: fixed-width files\n- `read_table()`: whitespace-separated files\n- `read_log()`: web log files\n\nTo read `.csv` files, include a path and (optionally) a column specification in `col_types`:\n\n```r\n# (1) pass only the path; readr guesses col_types \nread_csv(file='path/to/file.csv')\n\n# (2) include a column specification with col_types\nread_csv(\n    file='path/to/file.csv', \n    col_types = list( x = col_string(), y = col_skip() )\n)\n```\n\nWith no column specification, `readr` uses the the first 1000 rows to guess with a simple heuristic: \n\n- if column contains only T/F, `logical`\n- if only numbers, `double`\n- if ISO8601 standard,  `date` or `date-time`\n- otherwise `string`\n\nThere are 11 column types that can be specified: \n\n- `col_logical()` - reads as boolean TRUE FALSE values\n- `col_integer()` - reads as integer\n- `col_double()` - reads as double\n- `col_number()` - numeric parser that can ignore non-numbers\n- `col_character()` - reads as strings\n- `col_factor(levels, ordered = FALSE)` - creates factors\n- `col_datetime(format = \"\")` - creates date-times\n- `col_date(format = \"\")` - creates dates\n- `col_time(format = \"\")` - creates times\n- `col_skip()` - skips a column \n- `col_guess()` - tries to guess the column\n\nSome useful additional arguments:\n\n- if there is **no header** (the top row containing column names), include `col_names = FALSE`\n- to **provide a header**, include `col_names = c(\"x\",\"y\",\"z\")`\n- to **skip some lines**, include `skip = n`, where n is number of lines to skip\n- to **select which columns** to import, include `col_select(x, y)`\n- to **guess** column types **with all rows**, include `guess_max = Inf` \n\nSometimes weird things happen. The most common problems are: \n\n- **column contains unexpected values** - your dataset has a column that you expected to be `logical` or `double`, but there is a typo somewhere, so R has coerced the column into `character`. Solve by specifying the column type `col_double()` and then using the `problems()` function to see where R failed.\n- **missing values are not `NA`** - your dataset has missing values, but they were not coded as `NA` as R expects. Solve by adding an `na` argument (e.g. `na=c(\"N/A\")`)\n- **column names have spaces** - your dataset has column names that include spaces, breaking R's naming rules. In these cases, R adds backticks (e.g. `` `brain size` ``); we can use the `rename()` function to fix them. If we have a lot to rename and that gets annoying, see `janitor::clean_names()`.\n\n\nReading more complex file types requires functions outside the tidyverse:\n\n- **excel** with `readxl` - see [Spreadsheets](https://r4ds.hadley.nz/spreadsheets#excel) in R for Data Science\n- **google sheets**  with `googlesheets4` - see [Spreadsheets](https://r4ds.hadley.nz/spreadsheets#google-sheets) in R for Data Science\n- **databases** with `DBI` - see [Databases](https://r4ds.hadley.nz/databases) in R for Data Science\n- **json data** with `jsonlite` - see [Hierarchical data](https://r4ds.hadley.nz/rectangling) in R for Data Science\n\n## Writing data \n\nWe can also write to a csv file with:\n\n```r\nwrite_csv(our_tibble, \"name_of_file.csv\")\n```\n\n\n## Further reading and references\n\nRecommended further reading:\n\n- [Data tidying](https://r4ds.hadley.nz/data-tidy) in R for Data Science\n- [Tibbles](https://r4ds.had.co.nz/tibbles.html) in R for Data Science\n- [Data import](https://r4ds.hadley.nz/data-import.html) in R for Data Science\n- [readr cheatsheet](https://rstudio.github.io/cheatsheets/html/data-import.html?_gl=1*1fxlvya*_ga*MTI4NTg4NDIzMy4xNjkyODg0OTA4*_ga_2C0WZ1JHG0*MTY5Mjg4NDkwNy4xLjAuMTY5Mjg4NDkwNy4wLjAuMA..)\n\n","srcMarkdownNoYaml":"\n\n## Welcome to the tidyverse\n\n> The tidyverse is an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures. ~ [Tidyverse package docs](https://www.tidyverse.org/)\n\nThe `tidyverse` collection of packages includes: \n\n- `ggplot2` - for data visualization\n- `dplyr` - for data wrangling\n- `readr` - for reading data\n- `tibble` - for modern data frames\n- `stringr`: for string manipulation\n- `forcats`: for dealing with factors\n- `tidyr`: for data tidying\n- `purrr`: for functional programming\n- `lubridate`: for working with dates and times\n\nWe load the `tidyverse` like any other package, with `library(tidyverse)`. When we do, we will receive a message with (1) a list packages that were loaded and (2) a warning that there are potential conflicts with base R's `stats` functions\n\n- We can resolve conflicts with the `::` operator, which allows us to specify which package our intended function belongs to as a prefix: `stats::filter()` or `dplyr::filter()`\n\n## What is tidy data?\n\nThe same underlying data can be represented in a table in many different ways; some easier to work with than others. The tidyverse makes use of tidy data principles to make datasets easier to work with in R. **Tidy data** provides a standard way of structuring datasets: \n\n1. each variable forms a **column**; each column forms a variable\n2. each observation forms a **row**; each row forms an observation\n3. value is a **cell**; each cell is a single value\n\n\nWhy is tidy data easier to work with? \n\n- Because consistency and uniformity are very helpful when programming\n- Variables as columns works well for vectorized languages (R!)\n\n## Functional programming with purrr\n\n> purrr enhances R’s functional programming (FP) toolkit by providing a complete and consistent set of tools for working with functions and vectors. If you’ve never heard of FP before, the best place to start is the family of map() functions which allow you to replace many for loops with code that is both more succinct and easier to read.  ~ [purrr docs](https://purrr.tidyverse.org/)\n\nLet's illustrate the joy of the tidyverse with one of its packages: `purrr`. The docs say that the best place to start is the family of `map()` functions, so we'll do that.\n\nThe `map()` functions:\n\n1. take a vector as input\n2. apply a function to each element\n3. return a new vector\n\nWe say \"functions\" because there are 5, the generic `map()` function and `map_*()` variants for each type of vector: \n\n- `map()`\n- `map_lgl()`\n- `map_int()`\n- `map_dbl()`\n- `map_chr()` \n\nTo illustrate, suppose we have a data frame `df` with 3 columns and we want to compute the mean of each column. We could solve this with copy-and-paste (run `mean()` 3 different times) or try to use a `for` loop, but `map()` can do this with just one line: \n\n```r\n# We use `map_dbl()` because `mean()` returns a *double* value\nmap_dbl(df, mean)\n```\n\n\n## Modern data frames with tibble\n\n> A tibble, or tbl_df, is a modern reimagining of the data.frame, keeping what time has proven to be effective, and throwing out what is not. Tibbles are data.frames that are lazy and surly: they do less and complain more ~ [tibble docs](https://tibble.tidyverse.org/)\n\nTibbles do less than data frames, in a good way: \n\n- never changes type of input (never converts strings to factors!)\n- never changes the name of variables \n- only recycles vectors of length 1\n- never creates row names \n\nYou can read more in the [tibble vignette](https://tibble.tidyverse.org/articles/tibble.html) if you are interested, but understanding these differences is not necessary to be successful in the course. The take-away is that `data.frame` and `tibble` sometimes behave differently. The behavior of `tibble` makes more sense for modern data science, so we should us it instead!\n\nCreate a `tibble` with one of the following:  \n\n```r\n# (1) coerce an existing object (e.g., a data frame) to tibble\nas_tibble(x)\n\n# (2) construct a tibble from a column of vectors\ntibble(x=1:5, y=1)\n\n# (3) define row-by-row, short for transposed tibble\ntribble(\n    ~x, ~y, ~z,\n    \"a\", 2, 3.6,\n    \"b\", 1, 8.5\n)\n```\n\nWe will encounter two main ways tibbles and data frames differ: \n\n- **printing** - by default, tibbles print the first 10 rows and all columns that fit on screen, making it easier to work with large datasets. Tibbles also report the type of each column (e.g. `<dbl>`, `<chr>`)\n- **subsetting** - tibbles are more strict than data frames, which fixes two quirks we encountered last lecture when subsetting with `[[` and `$`: (1) tibbles *never* do partial matching, and (2) they *always* generate a warning if the column you are trying to extract does not exist.\n\nTo test if something is a `tibble` or a `data.frame`: \n\n- `is_tibble(x)`\n- `is.data.frame(x)`\n\n## Reading data with readr\n\n> The goal of readr is to provide a fast and friendly way to read rectangular data from delimited files, such as comma-separated values (CSV) and tab-separated values (TSV). It is designed to parse many types of data found in the wild, while providing an informative problem report when parsing leads to unexpected results.\n> \n> [readr docs](https://readr.tidyverse.org/)\n\nOften we want to read in some data we've generated or collected outside of R. The most basic and common format is plain-text **rectangular** files. We will \"read\" these into R with readr's `read_*()` functions.\n\nThe `read_*()` functions have two important arguments: \n\n- `file` - the path to the file (that reader will try to parse)\n- `col_types` - **column specification**, a description of how each column should be converted from a character vector to a specific data type\n\nThere are 7 supported file types, each with their own `read_*()` function:\n\n- `read_csv()`: comma-separated values (CSV)\n- `read_tsv()`: tab-separated values (TSV)\n- `read_csv2()`: semicolon-separated values\n- `read_delim()`: delimited files (CSV and TSV are important special cases)\n- `read_fwf()`: fixed-width files\n- `read_table()`: whitespace-separated files\n- `read_log()`: web log files\n\nTo read `.csv` files, include a path and (optionally) a column specification in `col_types`:\n\n```r\n# (1) pass only the path; readr guesses col_types \nread_csv(file='path/to/file.csv')\n\n# (2) include a column specification with col_types\nread_csv(\n    file='path/to/file.csv', \n    col_types = list( x = col_string(), y = col_skip() )\n)\n```\n\nWith no column specification, `readr` uses the the first 1000 rows to guess with a simple heuristic: \n\n- if column contains only T/F, `logical`\n- if only numbers, `double`\n- if ISO8601 standard,  `date` or `date-time`\n- otherwise `string`\n\nThere are 11 column types that can be specified: \n\n- `col_logical()` - reads as boolean TRUE FALSE values\n- `col_integer()` - reads as integer\n- `col_double()` - reads as double\n- `col_number()` - numeric parser that can ignore non-numbers\n- `col_character()` - reads as strings\n- `col_factor(levels, ordered = FALSE)` - creates factors\n- `col_datetime(format = \"\")` - creates date-times\n- `col_date(format = \"\")` - creates dates\n- `col_time(format = \"\")` - creates times\n- `col_skip()` - skips a column \n- `col_guess()` - tries to guess the column\n\nSome useful additional arguments:\n\n- if there is **no header** (the top row containing column names), include `col_names = FALSE`\n- to **provide a header**, include `col_names = c(\"x\",\"y\",\"z\")`\n- to **skip some lines**, include `skip = n`, where n is number of lines to skip\n- to **select which columns** to import, include `col_select(x, y)`\n- to **guess** column types **with all rows**, include `guess_max = Inf` \n\nSometimes weird things happen. The most common problems are: \n\n- **column contains unexpected values** - your dataset has a column that you expected to be `logical` or `double`, but there is a typo somewhere, so R has coerced the column into `character`. Solve by specifying the column type `col_double()` and then using the `problems()` function to see where R failed.\n- **missing values are not `NA`** - your dataset has missing values, but they were not coded as `NA` as R expects. Solve by adding an `na` argument (e.g. `na=c(\"N/A\")`)\n- **column names have spaces** - your dataset has column names that include spaces, breaking R's naming rules. In these cases, R adds backticks (e.g. `` `brain size` ``); we can use the `rename()` function to fix them. If we have a lot to rename and that gets annoying, see `janitor::clean_names()`.\n\n\nReading more complex file types requires functions outside the tidyverse:\n\n- **excel** with `readxl` - see [Spreadsheets](https://r4ds.hadley.nz/spreadsheets#excel) in R for Data Science\n- **google sheets**  with `googlesheets4` - see [Spreadsheets](https://r4ds.hadley.nz/spreadsheets#google-sheets) in R for Data Science\n- **databases** with `DBI` - see [Databases](https://r4ds.hadley.nz/databases) in R for Data Science\n- **json data** with `jsonlite` - see [Hierarchical data](https://r4ds.hadley.nz/rectangling) in R for Data Science\n\n## Writing data \n\nWe can also write to a csv file with:\n\n```r\nwrite_csv(our_tibble, \"name_of_file.csv\")\n```\n\n\n## Further reading and references\n\nRecommended further reading:\n\n- [Data tidying](https://r4ds.hadley.nz/data-tidy) in R for Data Science\n- [Tibbles](https://r4ds.had.co.nz/tibbles.html) in R for Data Science\n- [Data import](https://r4ds.hadley.nz/data-import.html) in R for Data Science\n- [readr cheatsheet](https://rstudio.github.io/cheatsheets/html/data-import.html?_gl=1*1fxlvya*_ga*MTI4NTg4NDIzMy4xNjkyODg0OTA4*_ga_2C0WZ1JHG0*MTY5Mjg4NDkwNy4xLjAuMTY5Mjg4NDkwNy4wLjAuMA..)\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"markdown"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../styles.css","../include/webex.css"],"toc":true,"number-sections":true,"include-in-header":["../include/webex.js"],"output-file":"data-importing.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.353","callout-appearance":"simple","theme":"cosmo","fontsize":"1em","linestretch":1.35,"number-depth":2,"grid":{"sidebar-width":"300px"},"title":"Data importing","date":"09/05/2023","author":["Katie Schuler"]},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}