{"title":"Practice quiz 4","markdown":{"yaml":{"title":"Practice quiz 4","subtitle":"Not graded, just practice","date":"2023-11-28","author":"Katie Schuler","number-sections":false},"headingText":"1 Model reliability","containsRefs":false,"markdown":"\n\n```{r}\n#| echo: false\n#| message: false\n\nlibrary(webexercises)\nlibrary(tidyverse)\nlibrary(optimg)\nlibrary(tidymodels)\ntheme_set(theme_gray(base_size = 16))\nset.seed(60)\n\ndata_n10 <- read_csv(\"http://kathrynschuler.com/datasets/model-reliability-sample10.csv\") \ndata_n200 <- read_csv(\"http://kathrynschuler.com/datasets/model-reliability-sample200.csv\") \n```\n\n\n\na. As we collect more data, our parameter estimates\n\n```{r}\n#| echo: false\n#| results: asis\n\n# Define the answer choices\nchoices <- c(\n    answer = \"become more reliable\",\n    \"become less reliable\", \n    \"stay the same\"\n)\n\ncat(longmcq(choices))\n```\n\nb. Each figure below plots 100 bootstrapped models with data drawn from the same population. In one figure, the model is fit to 10 data points. In the other, each model is fit to 200 data points. Which figure shows the model fit to 200 data points? \n\n```{r}\n#| echo: false\n#| layout-ncol: 2\n\nbootstrapped_fits <- data_n10 %>%\n  specify(y ~ x) %>%\n  generate(reps = 100, type = \"bootstrap\") %>%\n  fit()\n\nbootstrapped_fits_wide <- bootstrapped_fits %>%\n  spread(term, estimate)\n\nggplot(\n  data = data_n10,\n  mapping = aes(x = x, y = y)\n) +\n  geom_point(alpha = 0) +\n  geom_abline(data = bootstrapped_fits_wide,\n     aes(slope =  x, intercept = intercept, group = replicate), alpha = 0.05)  +\n  labs(tag = \"A\")\n\n\nbootstrapped_fits <- data_n200 %>%\n  specify(y ~ x) %>%\n  generate(reps = 100, type = \"bootstrap\") %>%\n  fit()\n\nbootstrapped_fits_wide <- bootstrapped_fits %>%\n  spread(term, estimate)\n\nggplot(\n  data = data_n200,\n  mapping = aes(x = x, y = y)\n) +\n  geom_point(alpha = 0) +\n  geom_abline(data = bootstrapped_fits_wide,\n     aes(slope =  x, intercept = intercept, group = replicate), alpha = 0.05)  +\n  #geom_smooth(method = \"lm\", formula = \"y ~ x\", se = FALSE, linewidth = 2) +\n  labs(tag = \"B\")\n\n```\n\n```{r}\n#| echo: false\n#| results: asis\n\n# Define the answer choices\nchoices <- c(\n    \"Figure A\",\n    answer = \"Figure B\", \n    \"Both figures have the same number of data points\"\n)\n\ncat(longmcq(choices))\n```\n\nc. As we collect more data, what happens to the confidence interval around our parameter estimates? \n\n```{r}\n#| echo: false\n#| results: asis\n\n# Define the answer choices\nchoices <- c(\n    \"It gets bigger (wider)\",\n    \"It stays the same\", \n    answer = \"It gets smaller (narrower)\"\n)\n\ncat(longmcq(choices))\n```\n\nd. True or false, we can obtain confidence intervals around parameter estimates for models in the same we we did for point estimates like the mean. \n\n```{r}\n#| echo: false\n#| results: asis\n\n# Define the answer choices\nchoices <- c(answer = \"True\", \"False\")\n\ncat(longmcq(choices))\n\n```\n\ne. Model reliability asks how certain we can be about our parameter estimates. Why is there uncertainty around our parameter estimates? \n\n```{r}\n#| code-fold: true\n#| code-summary: \"answer\"\n#| eval: false\n\"Because we are interested in the model parameters that \nbest describe the population from which the sample was\n drawn. Due to sampling error, we can expect some \n variability in the model parameters.\"\n\n```\n\nf. The figure below shows the model fit for a sample of 10 participants. Suppose we repeated our experiment with 10 new participants. True or false, fitting the same model to these new data would yield approximately the same parameter estimates. \n\n```{r}\n#| echo: false\n#| results: asis\n\n# Define the answer choices\nchoices <- c(\"True\", answer = \"False\")\n\ncat(longmcq(choices))\n\n```\n\ng. True or false, a model with high accuracy must also have high reliability.\n\n```{r}\n#| echo: false\n#| results: asis\n\n# Define the answer choices\nchoices <- c(\"True\", answer=\"False\")\n\ncat(longmcq(choices))\n\n```\n\n\n## Nonlinear models \n\na. The model `y ~ poly(x,2)` is plotted in which of the figures below? \n\n![](/include/figures/polys.png)\n\n```{r}\n#| echo: false\n#| results: asis\n\n# Define the answer choices\nchoices <- c(\n    \"1\",\n    \"2\",\n    answer=\"3\", \n    \"4\"\n)\n\ncat(longmcq(choices))\n```\n\n\nb. Which of the equations below expresses a quadratic polynomial model in R?  \n\n    1. `y ~ poly(x, 1)`\n    2. `y ~ poly(x, 2)`\n    3. `y ~ poly(x, 3)`\n    4. `y ~ poly(x, 4)`\n\n\n```{r}\n#| echo: false\n#| results: asis\n\n# Define the answer choices\nchoices <- c(\n    \"1\",\n    answer =\"2\",\n    \"3\", \n    \"4\"\n)\n\ncat(longmcq(choices))\n```\n\nc. True or false, `lm()` can be used to fit a linearized nonlinear model. \n\n```{r}\n#| echo: false\n#| results: asis\n\n# Define the answer choices\nchoices <- c(answer=\"True\", \"False\")\n\ncat(longmcq(choices))\n\n```\n\nd. Fill in each blank below with the model building process best described by the definition: \n\n    - `r mcq(c(\"model specification\", answer =  \"model fitting\", \"model accuracy\", \"model reliability\"))` is finding the best fitting parameter estimates.\n    - `r mcq(c(\"model specification\", \"model fitting\", \"model accuracy\", answer =  \"model reliability\"))` is quantifying the uncertainty on the parameter estimates.\n    - `r mcq(c(answer =  \"model specification\", \"model fitting\", \"model accuracy\", \"model reliability\"))` is choosing the type of model and its functional form.\n    - `r mcq(c(\"model specification\", \"model fitting\", answer =  \"model accuracy\", \"model reliability\"))` is quantifying how well our model fits our data. \n\n\n## 3 Classification \n\na. Which of the following aspects of model building apply to classification models? (Choose all that apply)\n\n```{r}\n#| echo: false\n#| results: asis\n\n# Define the answer choices\nchoices <- c(\n    answer=\"specify\",\n    answer=\"fit\",\n    answer=\"accuracy\", \n    answer=\"reliability\"\n)\n\ncat(longmcq(choices))\n```\n\nb. What is the difference between regression and classification? \n\n```{r}\n#| code-fold: true\n#| code-summary: \"answer\"\n#| eval: false\n\"Regression predicts a continuous response varaible, \nclassification predicts a discrete response variable\"\n\n```\n\nc. Which accuracy metric is best applied to classification models? \n\n```{r}\n#| echo: false\n#| results: asis\n\n# Define the answer choices\nchoices <- c(\n    \"R squared\",\n    \"RMSE\",\n    answer =\"Pecent correct\",\n    \"All of the above\"\n)\n\ncat(longmcq(choices))\n```\n\nd. In the figure below, which aspect shows the response variable? \n\n![](/include/figures/pquiz4-3d.png)\n\n```{r}\n#| echo: false\n#| results: asis\n\n# Define the answer choices\nchoices <- c(\n    \"x-axis\",\n    \"y-axis\",\n    answer =\"color of points\",\n    \"blue line\"\n)\n\ncat(longmcq(choices))\n```\n\ne. Which figure below could show a plotted classification model? Choose all that apply.\n\n![](/include/figures/pquiz4-3e.png)\n\n\n```{r}\n#| echo: false\n#| results: asis\n\n# Define the answer choices\nchoices <- c(\n    answer = \"Figure A\",\n    answer = \"Figure B\",\n    answer = \"Figure C\"\n)\n\ncat(longmcq(choices))\n```\n\n\nf. Name two kinds of linear classifiers\n\n```{r}\n#| code-fold: true\n#| code-summary: \"answer\"\n#| eval: false\n\"Any 2 of those mentioned in class: \nLogistic regression\nLinear discriminant analysis (LDA)\nLinear support vector machines (SVM)\nNearest-prototype classifiers\nNaive Bayes classifiers\n\"\n\n```\n\n\n## 4 Classification in R \n\na. We can impliment classification via `r mcq(c(\"linear regression\", \"cubic polynomials\", answer =  \"logistic regression\", \"nearest-neighbor regression\", \"all of the above\"))`\n\nb. True or false, in R, we can perform logistic regression with a generalized linear model. \n\n```{r}\n#| echo: false\n#| results: asis\n\n# Define the answer choices\nchoices <- c(answer=\"True\", \"False\")\n\ncat(longmcq(choices))\n\n```\n\nc. What 3 elements do all GLMs have? \n\n```{r}\n#| code-fold: true\n#| code-summary: \"answer\"\n#| eval: false\n\"1. A particular distribution for modeling the response variable\n2. A linear model \n3. A link function\n\"\n\n```\n\nd. What is the link function for logistic regression? \n\n```{r}\n#| echo: false\n#| results: asis\n\n# Define the answer choices\nchoices <- c(\n    answer = \"logistic function\", \n    \"polynomial expansion\",\n    \"log transformation\",\n    \"inverse transformation\"\n)\n\ncat(longmcq(choices))\n\n```\n\nf. Which of the following fits a logistic regression model in R? Choose one.\n\n\n```r\n# code A\nglm(y ~ x, data = data, family = \"binomial\")\n\n# code B\ndata %>%\n    specify(y ~ x) %>%\n    fit() \n\n# code C \nlogistic_reg %>%\n    set_engine(\"glm\") %>%\n    fit(y ~ x, data = data)\n```\n\n```{r}\n#| echo: false\n#| results: asis\n\n# Define the answer choices\nchoices <- c(\n    \"code A\", \n    \"code B\",\n    \"code C\",\n    \"code A and B only\",\n    answer = \"all of the above\"\n)\n\ncat(longmcq(choices))\n\n```\n\n\n\n\n\n\n\n\n\n\n\n\n","srcMarkdownNoYaml":"\n\n```{r}\n#| echo: false\n#| message: false\n\nlibrary(webexercises)\nlibrary(tidyverse)\nlibrary(optimg)\nlibrary(tidymodels)\ntheme_set(theme_gray(base_size = 16))\nset.seed(60)\n\ndata_n10 <- read_csv(\"http://kathrynschuler.com/datasets/model-reliability-sample10.csv\") \ndata_n200 <- read_csv(\"http://kathrynschuler.com/datasets/model-reliability-sample200.csv\") \n```\n\n\n## 1 Model reliability \n\na. As we collect more data, our parameter estimates\n\n```{r}\n#| echo: false\n#| results: asis\n\n# Define the answer choices\nchoices <- c(\n    answer = \"become more reliable\",\n    \"become less reliable\", \n    \"stay the same\"\n)\n\ncat(longmcq(choices))\n```\n\nb. Each figure below plots 100 bootstrapped models with data drawn from the same population. In one figure, the model is fit to 10 data points. In the other, each model is fit to 200 data points. Which figure shows the model fit to 200 data points? \n\n```{r}\n#| echo: false\n#| layout-ncol: 2\n\nbootstrapped_fits <- data_n10 %>%\n  specify(y ~ x) %>%\n  generate(reps = 100, type = \"bootstrap\") %>%\n  fit()\n\nbootstrapped_fits_wide <- bootstrapped_fits %>%\n  spread(term, estimate)\n\nggplot(\n  data = data_n10,\n  mapping = aes(x = x, y = y)\n) +\n  geom_point(alpha = 0) +\n  geom_abline(data = bootstrapped_fits_wide,\n     aes(slope =  x, intercept = intercept, group = replicate), alpha = 0.05)  +\n  labs(tag = \"A\")\n\n\nbootstrapped_fits <- data_n200 %>%\n  specify(y ~ x) %>%\n  generate(reps = 100, type = \"bootstrap\") %>%\n  fit()\n\nbootstrapped_fits_wide <- bootstrapped_fits %>%\n  spread(term, estimate)\n\nggplot(\n  data = data_n200,\n  mapping = aes(x = x, y = y)\n) +\n  geom_point(alpha = 0) +\n  geom_abline(data = bootstrapped_fits_wide,\n     aes(slope =  x, intercept = intercept, group = replicate), alpha = 0.05)  +\n  #geom_smooth(method = \"lm\", formula = \"y ~ x\", se = FALSE, linewidth = 2) +\n  labs(tag = \"B\")\n\n```\n\n```{r}\n#| echo: false\n#| results: asis\n\n# Define the answer choices\nchoices <- c(\n    \"Figure A\",\n    answer = \"Figure B\", \n    \"Both figures have the same number of data points\"\n)\n\ncat(longmcq(choices))\n```\n\nc. As we collect more data, what happens to the confidence interval around our parameter estimates? \n\n```{r}\n#| echo: false\n#| results: asis\n\n# Define the answer choices\nchoices <- c(\n    \"It gets bigger (wider)\",\n    \"It stays the same\", \n    answer = \"It gets smaller (narrower)\"\n)\n\ncat(longmcq(choices))\n```\n\nd. True or false, we can obtain confidence intervals around parameter estimates for models in the same we we did for point estimates like the mean. \n\n```{r}\n#| echo: false\n#| results: asis\n\n# Define the answer choices\nchoices <- c(answer = \"True\", \"False\")\n\ncat(longmcq(choices))\n\n```\n\ne. Model reliability asks how certain we can be about our parameter estimates. Why is there uncertainty around our parameter estimates? \n\n```{r}\n#| code-fold: true\n#| code-summary: \"answer\"\n#| eval: false\n\"Because we are interested in the model parameters that \nbest describe the population from which the sample was\n drawn. Due to sampling error, we can expect some \n variability in the model parameters.\"\n\n```\n\nf. The figure below shows the model fit for a sample of 10 participants. Suppose we repeated our experiment with 10 new participants. True or false, fitting the same model to these new data would yield approximately the same parameter estimates. \n\n```{r}\n#| echo: false\n#| results: asis\n\n# Define the answer choices\nchoices <- c(\"True\", answer = \"False\")\n\ncat(longmcq(choices))\n\n```\n\ng. True or false, a model with high accuracy must also have high reliability.\n\n```{r}\n#| echo: false\n#| results: asis\n\n# Define the answer choices\nchoices <- c(\"True\", answer=\"False\")\n\ncat(longmcq(choices))\n\n```\n\n\n## Nonlinear models \n\na. The model `y ~ poly(x,2)` is plotted in which of the figures below? \n\n![](/include/figures/polys.png)\n\n```{r}\n#| echo: false\n#| results: asis\n\n# Define the answer choices\nchoices <- c(\n    \"1\",\n    \"2\",\n    answer=\"3\", \n    \"4\"\n)\n\ncat(longmcq(choices))\n```\n\n\nb. Which of the equations below expresses a quadratic polynomial model in R?  \n\n    1. `y ~ poly(x, 1)`\n    2. `y ~ poly(x, 2)`\n    3. `y ~ poly(x, 3)`\n    4. `y ~ poly(x, 4)`\n\n\n```{r}\n#| echo: false\n#| results: asis\n\n# Define the answer choices\nchoices <- c(\n    \"1\",\n    answer =\"2\",\n    \"3\", \n    \"4\"\n)\n\ncat(longmcq(choices))\n```\n\nc. True or false, `lm()` can be used to fit a linearized nonlinear model. \n\n```{r}\n#| echo: false\n#| results: asis\n\n# Define the answer choices\nchoices <- c(answer=\"True\", \"False\")\n\ncat(longmcq(choices))\n\n```\n\nd. Fill in each blank below with the model building process best described by the definition: \n\n    - `r mcq(c(\"model specification\", answer =  \"model fitting\", \"model accuracy\", \"model reliability\"))` is finding the best fitting parameter estimates.\n    - `r mcq(c(\"model specification\", \"model fitting\", \"model accuracy\", answer =  \"model reliability\"))` is quantifying the uncertainty on the parameter estimates.\n    - `r mcq(c(answer =  \"model specification\", \"model fitting\", \"model accuracy\", \"model reliability\"))` is choosing the type of model and its functional form.\n    - `r mcq(c(\"model specification\", \"model fitting\", answer =  \"model accuracy\", \"model reliability\"))` is quantifying how well our model fits our data. \n\n\n## 3 Classification \n\na. Which of the following aspects of model building apply to classification models? (Choose all that apply)\n\n```{r}\n#| echo: false\n#| results: asis\n\n# Define the answer choices\nchoices <- c(\n    answer=\"specify\",\n    answer=\"fit\",\n    answer=\"accuracy\", \n    answer=\"reliability\"\n)\n\ncat(longmcq(choices))\n```\n\nb. What is the difference between regression and classification? \n\n```{r}\n#| code-fold: true\n#| code-summary: \"answer\"\n#| eval: false\n\"Regression predicts a continuous response varaible, \nclassification predicts a discrete response variable\"\n\n```\n\nc. Which accuracy metric is best applied to classification models? \n\n```{r}\n#| echo: false\n#| results: asis\n\n# Define the answer choices\nchoices <- c(\n    \"R squared\",\n    \"RMSE\",\n    answer =\"Pecent correct\",\n    \"All of the above\"\n)\n\ncat(longmcq(choices))\n```\n\nd. In the figure below, which aspect shows the response variable? \n\n![](/include/figures/pquiz4-3d.png)\n\n```{r}\n#| echo: false\n#| results: asis\n\n# Define the answer choices\nchoices <- c(\n    \"x-axis\",\n    \"y-axis\",\n    answer =\"color of points\",\n    \"blue line\"\n)\n\ncat(longmcq(choices))\n```\n\ne. Which figure below could show a plotted classification model? Choose all that apply.\n\n![](/include/figures/pquiz4-3e.png)\n\n\n```{r}\n#| echo: false\n#| results: asis\n\n# Define the answer choices\nchoices <- c(\n    answer = \"Figure A\",\n    answer = \"Figure B\",\n    answer = \"Figure C\"\n)\n\ncat(longmcq(choices))\n```\n\n\nf. Name two kinds of linear classifiers\n\n```{r}\n#| code-fold: true\n#| code-summary: \"answer\"\n#| eval: false\n\"Any 2 of those mentioned in class: \nLogistic regression\nLinear discriminant analysis (LDA)\nLinear support vector machines (SVM)\nNearest-prototype classifiers\nNaive Bayes classifiers\n\"\n\n```\n\n\n## 4 Classification in R \n\na. We can impliment classification via `r mcq(c(\"linear regression\", \"cubic polynomials\", answer =  \"logistic regression\", \"nearest-neighbor regression\", \"all of the above\"))`\n\nb. True or false, in R, we can perform logistic regression with a generalized linear model. \n\n```{r}\n#| echo: false\n#| results: asis\n\n# Define the answer choices\nchoices <- c(answer=\"True\", \"False\")\n\ncat(longmcq(choices))\n\n```\n\nc. What 3 elements do all GLMs have? \n\n```{r}\n#| code-fold: true\n#| code-summary: \"answer\"\n#| eval: false\n\"1. A particular distribution for modeling the response variable\n2. A linear model \n3. A link function\n\"\n\n```\n\nd. What is the link function for logistic regression? \n\n```{r}\n#| echo: false\n#| results: asis\n\n# Define the answer choices\nchoices <- c(\n    answer = \"logistic function\", \n    \"polynomial expansion\",\n    \"log transformation\",\n    \"inverse transformation\"\n)\n\ncat(longmcq(choices))\n\n```\n\nf. Which of the following fits a logistic regression model in R? Choose one.\n\n\n```r\n# code A\nglm(y ~ x, data = data, family = \"binomial\")\n\n# code B\ndata %>%\n    specify(y ~ x) %>%\n    fit() \n\n# code C \nlogistic_reg %>%\n    set_engine(\"glm\") %>%\n    fit(y ~ x, data = data)\n```\n\n```{r}\n#| echo: false\n#| results: asis\n\n# Define the answer choices\nchoices <- c(\n    \"code A\", \n    \"code B\",\n    \"code C\",\n    \"code A and B only\",\n    answer = \"all of the above\"\n)\n\ncat(longmcq(choices))\n\n```\n\n\n\n\n\n\n\n\n\n\n\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../styles.css","../include/webex.css"],"toc":true,"number-sections":false,"include-in-header":["../include/webex.js"],"output-file":"lab-08.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.353","callout-appearance":"simple","theme":"cosmo","fontsize":"1em","linestretch":1.35,"number-depth":2,"grid":{"sidebar-width":"300px"},"title":"Practice quiz 4","subtitle":"Not graded, just practice","date":"2023-11-28","author":"Katie Schuler"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}